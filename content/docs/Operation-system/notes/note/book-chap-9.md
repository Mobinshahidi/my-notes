---
title: book, chap 9
description: book, chap 9
---

# Chapter 9: Main Memory üíæ

## 9.1 Background

### 9.1.1 Basic Hardware üñ•Ô∏è

#### Memory and Addressing
- **Memory**: Consists of a large array of bytes, each with its own address
- **Basic execution cycle**: CPU fetches instructions from memory using program counter (PC), may fetch/store data from memory using addresses

#### Hardware Address Protection
- **Base and Limit Registers**:
  - **Base register**: Contains smallest legal physical memory address
  - **Limit register**: Specifies size of the range
  - **Protection**: Memory outside defined range is protected

#### Address Binding Process
- **Compile time**: If memory location known a priori, absolute code generated
- **Load time**: If memory location not known at compile time, relocatable code generated
- **Execution time**: If process can be moved during execution, binding delayed until run time

#### Hardware Support Requirements
- **Memory Management Unit (MMU)**: Hardware device that maps virtual to physical addresses
- **Dynamic relocation**: Using relocation register (base register) at runtime
- **Address translation**: Virtual address + relocation register = physical address

### 9.1.2 Address Binding üîó

#### Types of Addresses
- **Logical Address (Virtual Address)**: Generated by CPU, what program sees
- **Physical Address**: Actual address in memory hardware
- **Address Space**: Set of all logical/physical addresses

#### Address Translation Process
1. **Compile-time binding**: Logical and physical addresses are same
2. **Load-time and execution-time binding**: Logical and physical addresses differ
3. **Runtime translation**: Done by MMU hardware

#### Memory Management Unit (MMU)
- **Function**: Maps logical addresses to physical addresses
- **Simple scheme**: Add relocation register value to every logical address
- **User process**: Never sees real physical addresses, only logical addresses

### 9.1.3 Dynamic Loading üì•

#### Concept and Benefits
- **Dynamic Loading**: Routine loaded only when called
- **Advantage**: Better memory-space utilization, unused routines never loaded
- **Implementation**: Can be done without OS support, though OS can provide library support

#### Process
1. **Initial state**: Main program loaded into memory and executed
2. **Routine call**: If routine not loaded, relocatable linking loader called
3. **Loading**: Loader loads desired routine into memory and updates program's address tables
4. **Control transfer**: Control passed to newly loaded routine

#### Use Cases
- **Large amounts of code**: Handle infrequently occurring cases (error routines)
- **Memory optimization**: Only load what's actually needed
- **Runtime flexibility**: Can load different versions of routines based on conditions

## 9.2 Swapping üîÑ

### Basic Swapping Concept
- **Swapping**: Process can be temporarily swapped out of memory to backing store, then brought back for continued execution
- **Backing store**: Fast disk large enough to accommodate copies of all memory images for all users

### Swapping Process
1. **Swap out**: Remove process from memory to backing store
2. **Swap in**: Load process from backing store to memory
3. **Context switching**: Major part of context-switch time is swap time

### Implementation Details

#### Address Space Considerations
- **Dynamic relocation**: Process can be swapped back into different memory space
- **Address binding**: Must be done at execution time if swapping used
- **Memory compaction**: May be needed to create larger free memory blocks

#### Performance Factors
- **Transfer time**: Proportional to amount of memory swapped
- **Swap time calculation**: 
  - Transfer time = (amount of data) / (transfer rate)
  - Total time = transfer time + disk latency time

#### Constraints and Limitations
- **I/O operations**: Process with pending I/O cannot be swapped out
- **Buffer management**: OS must track which processes have I/O buffers
- **Memory requirements**: Process size cannot exceed physical memory

### Mobile System Considerations
- **iOS**: No swapping due to flash memory limitations
- **Android**: Limited swapping, uses different memory management strategies
- **Constraints**: Flash memory wear, limited write cycles

## 9.3 Contiguous Memory Allocation üì¶

### Memory Allocation Strategies

#### Fixed Partitioning
- **Multiple-partition method**: Divide memory into several fixed-sized partitions
- **Partition assignment**: Each partition contains exactly one process
- **Degree of multiprogramming**: Limited by number of partitions

#### Variable Partitioning
- **Dynamic partitioning**: Partitions created dynamically based on process needs
- **Hole management**: Keep track of available memory blocks (holes)
- **Allocation algorithms**: First-fit, best-fit, worst-fit

### Dynamic Storage Allocation Problem

#### First-Fit Algorithm
- **Strategy**: Allocate first hole that is big enough
- **Implementation**: Search from beginning of list
- **Advantage**: Fast allocation
- **Disadvantage**: May create small unusable holes at beginning

#### Best-Fit Algorithm
- **Strategy**: Allocate smallest hole that is big enough
- **Implementation**: Search entire list or keep sorted by size
- **Advantage**: Minimizes wasted space per allocation
- **Disadvantage**: Slow, creates very small holes

#### Worst-Fit Algorithm
- **Strategy**: Allocate largest available hole
- **Implementation**: Search entire list or keep sorted by size
- **Advantage**: Remaining hole may be useful
- **Disadvantage**: Generally poor performance

### Fragmentation Issues

#### External Fragmentation
- **Problem**: Total memory space exists but is not contiguous
- **Cause**: Memory allocation/deallocation creates unusable small holes
- **Solution**: Compaction to shuffle memory contents

#### Internal Fragmentation
- **Problem**: Allocated memory may be larger than requested
- **Cause**: Memory allocation in fixed-size blocks
- **Example**: Request 18,464 bytes, get 18,496 bytes (32 bytes wasted)

#### Memory Compaction
- **Purpose**: Reduce external fragmentation
- **Process**: Move all processes to one end of memory
- **Cost**: Expensive due to copying overhead
- **Requirement**: Dynamic relocation capability

## 9.5 Paging

### 9.5.1 Basic Method üìÑ

#### Paging Fundamentals
- **Physical memory**: Divided into fixed-size blocks called **frames**
- **Logical memory**: Divided into same-size blocks called **pages**
- **Page size**: Typically power of 2 (512 bytes to 1 GB)
- **Advantage**: Eliminates external fragmentation

#### Address Translation in Paging
- **Logical address**: Divided into page number (p) and page offset (d)
- **Page number**: Used as index into page table
- **Page offset**: Combined with base address to define physical address
- **Formula**: physical address = (frame number √ó page size) + offset

#### Page Table Structure
- **Purpose**: Maps logical pages to physical frames
- **Location**: Usually stored in main memory
- **Access**: One entry per page of logical address space
- **Content**: Frame number where page is stored

#### Hardware Support
- **Page-table base register (PTBR)**: Points to page table
- **Page-table length register (PTLR)**: Indicates size of page table
- **Memory access time**: Every memory access requires two memory accesses (page table + actual data)

#### Example: 32-bit Address with 4KB Pages
```
Logical address: 32 bits
Page size: 4KB = 2^12 bytes
Page offset: 12 bits (0-11)
Page number: 20 bits (12-31)
Maximum pages: 2^20 = 1,048,576 pages
```

### 9.5.2 Hardware Support üîß

#### Translation Look-aside Buffer (TLB)
- **Purpose**: Cache for page table entries to speed up address translation
- **Content**: Small number of page table entries (64-1024)
- **Implementation**: Associative memory (parallel search)
- **Hit ratio**: Percentage of times page number found in TLB

#### TLB Operation Process
1. **TLB lookup**: Check if page number is in TLB
2. **TLB hit**: Use frame number from TLB directly
3. **TLB miss**: Access page table in memory, update TLB
4. **Address translation**: Combine frame number with offset

#### Performance Analysis
- **TLB hit time**: 1 memory access (data only)
- **TLB miss time**: 2 memory accesses (page table + data)
- **Effective access time**: (hit ratio √ó hit time) + (miss ratio √ó miss time)

#### Example Calculation
```
TLB hit ratio: 80%
Memory access time: 100 nanoseconds
TLB access time: 20 nanoseconds

Effective access time = 0.8 √ó (20 + 100) + 0.2 √ó (20 + 100 + 100)
                      = 0.8 √ó 120 + 0.2 √ó 220
                      = 96 + 44 = 140 nanoseconds
```

#### Memory Protection in Paging
- **Protection bits**: Associated with each frame in page table
- **Read-only pages**: Code pages marked as read-only
- **Read-write pages**: Data and stack pages
- **Valid-invalid bit**: Indicates if page is in process's logical address space

#### Shared Pages
- **Reentrant code**: Can be shared among processes
- **Benefits**: Saves memory when multiple processes use same program
- **Requirements**: Code must be reentrant (non-self-modifying)
- **Implementation**: Multiple page tables point to same frames
